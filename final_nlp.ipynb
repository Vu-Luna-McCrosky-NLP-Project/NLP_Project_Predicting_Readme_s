{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7e39af",
   "metadata": {},
   "source": [
    "# Natural Language Processing Project\n",
    "#### By: Lupe Luna, Forrest McCrosky, and Anna Vu\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801b841",
   "metadata": {},
   "source": [
    "We will be using web scraping to extract some of the most-starred repositories on Github, and build a multi-classification model to predict what the most predominant programming language used will be based off of the README.md contents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f006a9a",
   "metadata": {},
   "source": [
    "[View this journal in jupyter nbviewer](https://nbviewer.jupyter.org/github/Vu-Luna-McCrosky-NLP-Project/NLP_Project_Predicting_Readme_s/blob/master/final_nlp.ipynb)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce975a31",
   "metadata": {},
   "source": [
    "# Agenda:\n",
    "---\n",
    "- [Executive Summary](#executive_summary)\n",
    " - [Project Planning](#project_planning)\n",
    " - [Imports](#imports)\n",
    " - [Data Acquisition](#data_acquisition)\n",
    " - [Data Preparation](#data_preparation)\n",
    " - [Data Exploration](#data_exploration)\n",
    " - [Statistical Testing](#stats)\n",
    " - [Modeling](#modeling)\n",
    " - [Test](#test)\n",
    " - [Conclusion and Next Steps](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0db7c1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466cbf37",
   "metadata": {},
   "source": [
    "<a id='executive_summary'></a>\n",
    "# Executive Summary:\n",
    "---\n",
    "To predict the most used programming language for each repository, we used a KNN model (fit with TD-IDF vectorizer) to predict with:\n",
    " - 82% accuracy\n",
    " - 82% precision\n",
    " - 76% recall\n",
    " \n",
    "based off of the README's contents on out of sample data.\n",
    "\n",
    "Our model does better predicting the result of a repository if its programming language is JavaScript or Python. For next time, we could probably use a bigger sample of repositories to help it account for Java, Go, and other languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f4b95",
   "metadata": {},
   "source": [
    "<a id='project_planning'></a>\n",
    "# Project Planning:\n",
    "---\n",
    "We're going to need to use web scraping in order to get ~200 repositories from [Github](www.github.com), once we bring in these in, we will filter for desirable README contents (language, size, etc.) We need to use the content of at least 100 READMEs, so to best ensure they will have valuable information, we are going to scrape our data from the [most starred repositories](https://github.com/search?q=stars%3A%3E0&s=stars&type=Repositories) on Github. \n",
    "\n",
    "After we follow the steps of the data science pipeline, we'll need to set up a couple of slides to present our findings.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cfbe83",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d0cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our modules\n",
    "import acquire as a\n",
    "import prepare as p\n",
    "import explore as e\n",
    "import model as m\n",
    "\n",
    "#import our most-used libraries \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "#import NLP neccessities\n",
    "import nltk\n",
    "import re\n",
    "from pprint import pprint\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import bs4\n",
    "import time\n",
    "\n",
    "#import sklearn for our models\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text, export_graphviz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123cb52",
   "metadata": {},
   "source": [
    "<a id='data_acquisition'></a>\n",
    "# Data Acquisition: \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d63ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use acquire function that built a repo list from github.com's most starred repositories\n",
    "\n",
    "repos = a.get_repo_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097677ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the repo list is: 200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['freeCodeCamp/freeCodeCamp',\n",
       " '996icu/996.ICU',\n",
       " 'EbookFoundation/free-programming-books',\n",
       " 'jwasham/coding-interview-university',\n",
       " 'vuejs/vue',\n",
       " 'facebook/react']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'The length of the repo list is: {len(repos)}\\n') ## <-- quality assurance check\n",
    "\n",
    "repos[:6] ## looking at some readme titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a5fc0",
   "metadata": {},
   "source": [
    "### Intial Repo List Function\n",
    " \n",
    " - get_repo_list() is designed to create a repo list from the most starred repositories on Github.\n",
    "    \n",
    " - The function loops through 20 pages with 10 results per page of the most starred repos on github using a range from 1 to 21.\n",
    "    \n",
    " - It then uses another loop to pull out all the titles of each repo using the beautiful soup library and html per page. It will also remove null elements and white spaces.\n",
    "    \n",
    " - After get_repo list ran, we manually removed 6 repositories from the list that were poorly formatted and not repository titles. \n",
    " - This leaves us 198 repos.\n",
    "    \n",
    "    \n",
    " - Since it does take a while to run and grab 200 repositiories (and you'll need your own Github token to have it function properly), we decided to create a .csv as an endproduct for our usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20300fcb",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbb0a5",
   "metadata": {},
   "source": [
    "Ran acquire.py from the terminal, and brought in our .json file as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0beff72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5f457d91383a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## reading our json file built from the acquire.py into a df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data2.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m             )\n\u001b[1;32m   1081\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "## reading our json file built from the acquire.py into a df\n",
    "\n",
    "df = pd.read_json('data2.json') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef0010",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now we are going to filter for the top four languages. We found them to be JavaScript, Python, Java, and Go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making a list of the top four used programming languages\n",
    "\n",
    "top_four = df.language.value_counts().keys()[0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d150b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filtering down dataframe to contain top four langauges\n",
    "\n",
    "df = df[df.language.isin(top_four)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() ## <-- quality assurance check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366c637",
   "metadata": {},
   "source": [
    "<br>\n",
    "Create a .csv, from the steps above, to be able to bring up this data faster as we work through the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NLP_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df25ad1",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's bring in the data with NLP_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eeb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in NLP_df.csv as a pandas dataframe\n",
    "df = a.get_github_data()\n",
    "\n",
    "#look at our dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba2375",
   "metadata": {},
   "source": [
    "### Acquisition Takeaways:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a0769",
   "metadata": {},
   "source": [
    " - New features could be made, like character count and word count. \n",
    " - Notice non-English characters in the contents\n",
    " - Need to clean the readme_contents\n",
    " - Duplicates were dropped while bringing in the data\n",
    " - We went from 200 to 109 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5cf756",
   "metadata": {},
   "source": [
    "<a id='data_preparation'></a>\n",
    "# Data Preparation:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30083741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this prep function will clean our readme_contents, and create readme_length and word_count features\n",
    "df = p.prep_github_data(df, 'readme_contents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1801a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the results of the prep function\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking target variables distribution\n",
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de1cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split our data into train, validate, and test sets\n",
    "train, validate, test = p.split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b410f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assure the shapes are reasonable\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc7c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the balance of our train target variables\n",
    "train.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a800f1",
   "metadata": {},
   "source": [
    "### Preparation Takeaways: \n",
    " - We have a clean set of readme_contents that we can explore on\n",
    " - Any READMEs with less than 10 words were dropped\n",
    " - Proceed to explore on our train set\n",
    " - We need to categorize content based on its dominant programming language, so we can find what words can help our model decifer what language is being used the most"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ffa2d4",
   "metadata": {},
   "source": [
    "<a id='data_exploration'></a>\n",
    "# Data Exploration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc33080",
   "metadata": {},
   "source": [
    "We are going to separate the clean README contents based on its repository's dominant programming language, and also have an inclusive one. We're only going to be exploring on our train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#content and its words put under the repository's primary language\n",
    "javascript_words = ' '.join(train[train.language == 'JavaScript'].clean)\n",
    "python_words = ' '.join(train[train.language == 'Python'].clean)\n",
    "java_words = ' '.join(train[train.language == 'Java'].clean)\n",
    "go_words = ' '.join(train[train.language == 'Go'].clean)\n",
    "all_words = ' '.join(train.clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe86049",
   "metadata": {},
   "source": [
    "Now we're going to split the content into individual words by splitting them based on spaces, and take a value counts to see how often each word comes up for each programming language. (Also did a frequency count for all words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e857b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up content into indivdual words, and count how many times the word comes up over all readmes\n",
    "javascript_freq = pd.Series(javascript_words.split()).value_counts()\n",
    "python_freq = pd.Series(python_words.split()).value_counts()\n",
    "java_freq = pd.Series(java_words.split()).value_counts()\n",
    "go_freq = pd.Series(go_words.split()).value_counts()\n",
    "all_freq = pd.Series(all_words.split()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc2b784",
   "metadata": {},
   "source": [
    "Now we will combine all of the frequencies, so we can view the words and how often they are used across the four languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2069837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df of frequencies of each word by language \n",
    "word_counts = pd.concat([javascript_freq, python_freq, java_freq, go_freq, all_freq], axis=1).fillna(0).astype(int)\n",
    "\n",
    "#name the columns\n",
    "word_counts.columns = ['javascript', 'python','java','go','all']\n",
    "\n",
    "#check our most frequently occuring words\n",
    "word_counts.sort_values('all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab883d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting By Java and JavaScript both in descending order to look for overlap\n",
    "word_counts.sort_values(['java', 'javascript'], ascending=[False, False]).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting By Python and Go\n",
    "word_counts.sort_values(['python', 'go'], ascending=[False, False]).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317644a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting By Python and Java\n",
    "word_counts.sort_values(['python', 'java'], ascending=[False, False]).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 25,631 different 'words' in our train dataset\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912246a",
   "metadata": {},
   "source": [
    "Let's compare programming languages and how much they use any of the overall top 20 words across all READMEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c2157",
   "metadata": {},
   "source": [
    "#### Most Frequent Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da2df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.javascript_barh(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.python_barh(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.java_barh(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.go_barh(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca127c",
   "metadata": {},
   "source": [
    "#### Word Overlap Per Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5120c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=18)\n",
    "(word_counts.sort_values(by='all', ascending=False)\n",
    " .head(20)\n",
    " .apply(lambda row: row / row['all'], axis=1)\n",
    " .drop(columns='all')\n",
    " .sort_values(by='javascript')\n",
    " .plot.barh(stacked=True, width=1, ec='black', figsize=(17,9)))\n",
    "plt.legend(bbox_to_anchor= (1.03, 1))\n",
    "plt.title('Word Overlap Per Langauge: Sorted by JavaScript\\n')\n",
    "plt.xlabel('\\nProportion of Overlap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c013a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## proportion stacked bar charts sorted by Python\n",
    "\n",
    "plt.rc('font', size=18)\n",
    "(word_counts.sort_values(by='all', ascending=False)\n",
    " .head(20)\n",
    " .apply(lambda row: row / row['all'], axis=1)\n",
    " .drop(columns='all')\n",
    " .sort_values(by='python')\n",
    " .plot.barh(stacked=True, width=1, ec='black', figsize=(17,9)))\n",
    "plt.legend(bbox_to_anchor= (1.03, 1))\n",
    "plt.title('Word Overlap Per Langauge: Sorted by Python\\n')\n",
    "plt.xlabel('\\nProportion of Overlap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a65f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=18)\n",
    "(word_counts.sort_values(by='all', ascending=False)\n",
    " .head(20)\n",
    " .apply(lambda row: row / row['all'], axis=1)\n",
    " .drop(columns='all')\n",
    " .sort_values(by='java')\n",
    " .plot.barh(stacked=True, width=1, ec='black', figsize=(17,9)))\n",
    "plt.legend(bbox_to_anchor= (1.03, 1))\n",
    "plt.title('Word Overlap Per Langauge: Sorted by Java\\n')\n",
    "plt.xlabel('\\nProportion of Overlap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad386e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=18)\n",
    "(word_counts.sort_values(by='all', ascending=False)\n",
    " .head(20)\n",
    " .apply(lambda row: row / row['all'], axis=1)\n",
    " .drop(columns='all')\n",
    " .sort_values(by='go')\n",
    " .plot.barh(stacked=True, width=1, ec='black', figsize=(17,9)))\n",
    "plt.legend(bbox_to_anchor= (1.03, 1))\n",
    "plt.title('Word Overlap Per Langauge: Sorted by Go\\n')\n",
    "plt.xlabel('\\nProportion of Overlap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c090ae4",
   "metadata": {},
   "source": [
    "#### Single Word Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d017da",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_words = [javascript_words,python_words,java_words,go_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.simple_wordclouds(language_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b4ca1",
   "metadata": {},
   "source": [
    "### Bigrams and Trigrams per Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa10ff",
   "metadata": {},
   "source": [
    "#### Bigrams Per Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=12)\n",
    "pd.Series(nltk.bigrams(javascript_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common JavaScript Bigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93943eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(python_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common Python Bigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5add32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(java_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common Java Bigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfadc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(go_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common Go Bigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647a9d2",
   "metadata": {},
   "source": [
    "#### All Languages Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ae416",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.bigrams(all_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common All Language Bigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a80a6",
   "metadata": {},
   "source": [
    "#### Trigrams Per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.trigrams(javascript_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common JavaScript Trigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.trigrams(python_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common Python Trigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.trigrams(java_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common Java Trigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c404e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.trigrams(go_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common Go Trigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e906b3",
   "metadata": {},
   "source": [
    "#### All Languages Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ab66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(nltk.trigrams(all_words.split())).value_counts().head(10).plot.barh()\n",
    "plt.title('Top 10 Most Common All Language Trigrams\\n')\n",
    "plt.xlabel('\\nFrequency')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb802f",
   "metadata": {},
   "source": [
    "#### Bigram Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a series for the frequencies of the top 20 bigrams of all programming categories\n",
    "\n",
    "top_20_javascript_bigrams = pd.Series(nltk.bigrams(javascript_words.split()))\\\n",
    ".value_counts().head(20)\n",
    "\n",
    "top_20_python_bigrams = pd.Series(nltk.bigrams(python_words.split()))\\\n",
    ".value_counts().head(20)\n",
    "\n",
    "top_20_java_bigrams = pd.Series(nltk.bigrams(java_words.split()))\\\n",
    ".value_counts().head(20)\n",
    "\n",
    "top_20_go_bigrams = pd.Series(nltk.bigrams(go_words.split()))\\\n",
    ".value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7cc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using list comprehension to creat a dictionary of javascript bigrams as a dictionary\n",
    "## then making a wordcloud\n",
    "\n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_javascript_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Top Bigrams for JavaScript\\n')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using list comprehension to creat a dictionary of python bigrams as a dictionary\n",
    "## then making a wordcloud\n",
    "\n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_python_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Top Bigrams for Python\\n')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cbc6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using list comprehension to creat a dictionary of java bigrams as a dictionary\n",
    "## then making a wordcloud\n",
    "\n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_java_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Top Bigrams for Java\\n')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3554d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using list comprehension to creat a dictionary of go bigrams as a dictionary\n",
    "## then making a wordcloud\n",
    "\n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_go_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Top Bigrams for Go\\n')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37355384",
   "metadata": {},
   "source": [
    "#### Trigram Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_javascript_trigrams = pd.Series(nltk.ngrams(javascript_words.split(),3))\\\n",
    ".value_counts().head(20)\n",
    "\n",
    "top_20_python_trigrams = pd.Series(nltk.ngrams(python_words.split(),3))\\\n",
    ".value_counts().head(20)\n",
    "\n",
    "top_20_java_trigrams = pd.Series(nltk.ngrams(java_words.split(),3))\\\n",
    ".value_counts().head(20)\n",
    "\n",
    "top_20_go_trigrams = pd.Series(nltk.ngrams(go_words.split(),3))\\\n",
    ".value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {k[0] + ' ' + k[1] + ' ' +k[2]: v for k, v in top_20_javascript_trigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Top Trigrams for JavaScript\\n')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {k[0] + ' ' + k[1] + ' ' +k[2]: v for k, v in top_20_python_trigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Top Trigrams for Python\\n')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbd343",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {k[0] + ' ' + k[1] + ' ' +k[2]: v for k, v in top_20_java_trigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Top Trigrams for Java\\n')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16afd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {k[0] + ' ' + k[1] + ' ' +k[2]: v for k, v in top_20_go_trigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img)\n",
    "plt.title('Top Trigrams for Go\\n')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b83c7",
   "metadata": {},
   "source": [
    "### Exploration Takeaways: \n",
    " - JavaScript has the most use of the 20 most common words across all READMEs, followed up by Python.\n",
    " - Java and Go have very small proportions for the most frequent words.\n",
    " - Some of the words are not single words, but we will proceed as in the README, they were not separated by spaces.\n",
    " - Given that our data is mostly JavaScript and Python, our exploration seems reasonable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779f03f",
   "metadata": {},
   "source": [
    "<a id='stats'></a>\n",
    "# Statistical Testing:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d98b9",
   "metadata": {},
   "source": [
    "## 2 Tailed T-Test\n",
    "\n",
    "We will be testing for a difference of means between groups of programming languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating categorized dataframes for each target variable value for statistical \n",
    "## testing purposes\n",
    "\n",
    "python_df = train[train.language == 'Python'] ## creating a python df \n",
    "go_df = train[train.language == 'Go'] ## creating a go df\n",
    "java_df = train[train.language == 'Java'] ## creating a Java df\n",
    "javascript_df = train[train.language == 'JavaScript'] ## creating a JavaScript df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9e39d",
   "metadata": {},
   "source": [
    "### Comparing README Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 ## <-- Determining alpha for Readme Length Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e37ca8",
   "metadata": {},
   "source": [
    "<br>\n",
    "Python Vs. JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48325eec",
   "metadata": {},
   "source": [
    "$H_0$: There is no difference in means of Python repository character lengths and JavaScript repository character lengths\n",
    "\n",
    "$H_a$: There is a difference in means of Python repository character lengths and JavaScript repository character lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(python_df.readme_length,javascript_df.readme_length)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b5da6",
   "metadata": {},
   "source": [
    "<br>\n",
    "Python Vs. Go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9dc5ed",
   "metadata": {},
   "source": [
    "$H_0$: There is no difference in means of Python repository character lengths and Go repository character lengths\n",
    "\n",
    "$H_a$: There is a difference in means of Python repository character lengths and Go repository character lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297042cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(python_df.readme_length,go_df.readme_length)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c99a5",
   "metadata": {},
   "source": [
    "<br>\n",
    "Python vs. Java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd44851",
   "metadata": {},
   "source": [
    "$H_0$: There is no difference in means of Python repository character lengths and Java repository character lengths\n",
    "\n",
    "$H_a$: There is a difference in means of Python repository character lengths and Java repository character lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ce9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(python_df.readme_length,java_df.readme_length)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9de057",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### ReadMe Length Comparison Takeaways\n",
    "\n",
    " - All of the tailed t tests run on the different target variable values comparing readme character lengths returned insignifcant results.\n",
    " - All languages versus python returned p values greater than our alpha of 0.05. \n",
    " - We fail to reject the null hypothesis\n",
    " - Therefore we can conclude that readme character length is independent of what programming language the repositories are written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc0128",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Comparing Word Count Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 ## <-- Determining alpha for Word Count Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ca87f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Python vs. JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7be25",
   "metadata": {},
   "source": [
    "$H_0$: There is no difference in means of Python repository word counts and JavaScript repository word counts\n",
    "\n",
    "$H_a$: There is a difference in means of Python repository word counts and JavaScript repository word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(python_df.word_count,javascript_df.word_count)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d59291",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Python vs. Go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b54175",
   "metadata": {},
   "source": [
    "$H_0$: There is no difference in means of Python repository word counts and Go repository word counts\n",
    "\n",
    "$H_a$: There is a difference in means of Python repository word counts and Go repository word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09562e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(python_df.word_count,go_df.word_count)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0e30d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Python vs. Java\n",
    "\n",
    "\n",
    "$H_0$: There is no difference in means of Python repository word counts and Java repository word counts\n",
    "\n",
    "$H_a$: There is a difference in means of Python repository word counts and Java repository word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36312bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(python_df.word_count,java_df.word_count)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eaa31c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Word Count Comparison Takeaways\n",
    "\n",
    " - All of the tailed t tests run on the different target variable values comparing word count returned insignifcant results\n",
    " - All languages versus python returned p values greater than our alpha of 0.05 \n",
    " - We fail to reject the null hypothesis\n",
    " - Therefore we can conclude the word count of the readme is independent of what programming language the repositories are written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d785ff8",
   "metadata": {},
   "source": [
    "<a id='modeling'></a>\n",
    "# Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d58f5",
   "metadata": {},
   "source": [
    "We are going to use classification models in order to predict the programming language. \n",
    "We will use decision tree, random forest, logistic regression, KNN, and a Naive Bayes and emphasize on accuracy.\n",
    "\n",
    "\n",
    "The first step is to initiaize the TfidfVectorizer, and split our data into X and y sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize TfidfVectorizer, use single words, bigrams and trigrams\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
    "X = tfidf.fit_transform(df.clean)\n",
    "y = df.language\n",
    "\n",
    "#split the data into X_train, X_validate, X_test, y_train, y_validate, y_test\n",
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, test_size=.2, random_state=12, stratify = y)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, test_size=.2, random_state=12, stratify= y_train_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ededa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view some of the feature names being used \n",
    "pprint(df.clean)\n",
    "pd.DataFrame(X.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188b059",
   "metadata": {},
   "source": [
    "We should to establish a baseline. Let's see what the most common programming language is in our y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae23d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use most common programming language as baseline\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddc1e2",
   "metadata": {},
   "source": [
    "Our baseline model will assume that every repository's most used language is JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish the baseline\n",
    "train['baseline_prediction'] = 'JavaScript'\n",
    "baseline_score = round(accuracy_score(train.language, train.baseline_prediction),2)\n",
    "print(f'Our baseline score is {baseline_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1b876d",
   "metadata": {},
   "source": [
    "Now we will create a train and test dataframe, we will be able to add our predictions to it to evaluate how the models perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f285bf",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf208a50",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fd6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree fit to X and y train\n",
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "#prediction columns \n",
    "train['predicted'] = tree.predict(X_train)\n",
    "test['predicted'] = tree.predict(X_test)\n",
    "\n",
    "#train and validate scores to check for overfitness \n",
    "print(f'train score: {tree.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {tree.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy on train, confusion matrix, and classification report for decision tree\n",
    "m.model_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2375da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize our decision tree\n",
    "plt.figure(figsize=(16,9))\n",
    "plot_tree(tree)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree scores\n",
    "tree_accuracy = round(sklearn.metrics.accuracy_score(y_train, train.predicted),2)\n",
    "tree_precision = round(sklearn.metrics.precision_score(y_train, train.predicted, average='macro'),2)\n",
    "tree_recall = round(sklearn.metrics.recall_score(y_train, train.predicted, average='macro'),2)\n",
    "print('Scores for Decision Tree!')\n",
    "print('---------------------------')\n",
    "print(f'Our baseline score is {baseline_score}')\n",
    "print(f'Accuracy score is {tree_accuracy}')\n",
    "print(f'Precision score is {tree_precision}')\n",
    "print(f'Recall score is {tree_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbceefcf",
   "metadata": {},
   "source": [
    "<br>\n",
    "Our decision tree model seems a bit overfit on the training set, this may mean it will perform poorly on out of sample data. \n",
    "It does perform better than our baseline though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2de543",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141949c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest fit to our X and y train\n",
    "rf = RandomForestClassifier(random_state=906, max_depth = 2).fit(X_train, y_train)\n",
    "\n",
    "#prediction columns\n",
    "train['predicted'] = rf.predict(X_train)\n",
    "test['predicted'] = rf.predict(X_test)\n",
    "\n",
    "#check for overfitness\n",
    "print(f'train score: {rf.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {rf.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5accb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy on train, confusion matrix, and classification report for random forest\n",
    "m.model_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest scores\n",
    "rf_accuracy = round(sklearn.metrics.accuracy_score(y_train, train.predicted),2)\n",
    "rf_precision = round(sklearn.metrics.precision_score(y_train, train.predicted, average='macro'),2)\n",
    "rf_recall = round(sklearn.metrics.recall_score(y_train, train.predicted, average='macro'),2)\n",
    "print('Scores for Random Forest!')\n",
    "print('---------------------------')\n",
    "print(f'Our baseline score is {baseline_score}')\n",
    "print(f'Accuracy score is {rf_accuracy}')\n",
    "print(f'Precision score is {rf_precision}')\n",
    "print(f'Recall score is {rf_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a846fea3",
   "metadata": {},
   "source": [
    "<br>\n",
    "The random forest model does not predict for Python, Java, or Go. It actually predicts that every repository is JavaScript. It does not beat the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1366c0c9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ecbce",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit logistic regression to our X and y train\n",
    "lm = LogisticRegression(C=.6).fit(X_train, y_train)\n",
    "\n",
    "#prediction columns\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)\n",
    "\n",
    "#check for overfitness\n",
    "print(f'train score: {lm.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {lm.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy on train, confusion matrix, and classification report for logistic regression\n",
    "m.model_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f75120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression scores\n",
    "logit_accuracy = round(sklearn.metrics.accuracy_score(y_train, train.predicted),2)\n",
    "logit_precision = round(sklearn.metrics.precision_score(y_train, train.predicted, average='macro'),2)\n",
    "logit_recall = round(sklearn.metrics.recall_score(y_train, train.predicted, average='macro'),2)\n",
    "print('Scores for Logistic Regression!')\n",
    "print('---------------------------')\n",
    "print(f'Our baseline score is {baseline_score}')\n",
    "print(f'Accuracy score is {logit_accuracy}')\n",
    "print(f'Precision score is {logit_precision}')\n",
    "print(f'Recall score is {logit_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458cca0",
   "metadata": {},
   "source": [
    "<br>\n",
    "Logistic Regression only makes JavaScript and Python predictions (but it assumed everything was JavaScript except for one single Python one)\n",
    "\n",
    "Tied with the baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e79c7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79de8a8",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 9 for n_neighbors for single words\n",
    "#use 10 for n_neighbors bigrams and trigrams\n",
    "\n",
    "#fit KNN to our X and y train\n",
    "knn = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "\n",
    "#prediction columns\n",
    "train['predicted'] = knn.predict(X_train)\n",
    "test['predicted'] = knn.predict(X_test)\n",
    "\n",
    "#check for overfitness\n",
    "print(f'train score: {knn.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {knn.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003faf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy on train, confusion matrix, and classification report for KNN\n",
    "m.model_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn scores\n",
    "knn_accuracy = round(sklearn.metrics.accuracy_score(y_train, train.predicted),2)\n",
    "knn_precision = round(sklearn.metrics.precision_score(y_train, train.predicted, average='macro'),2)\n",
    "knn_recall = round(sklearn.metrics.recall_score(y_train, train.predicted, average='macro'),2)\n",
    "print('Scores for KNN!')\n",
    "print('---------------------------')\n",
    "print(f'Our baseline score is {baseline_score}')\n",
    "print(f'Accuracy score is {knn_accuracy}')\n",
    "print(f'Precision score is {knn_precision}')\n",
    "print(f'Recall score is {knn_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0bb615",
   "metadata": {},
   "source": [
    "Our KNN model beats the baseline, and does well at accurately predicting the repository's most used programming language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a36f73",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170300a",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're using a multinomial naive bayes fit to our X and y train\n",
    "nb = MultinomialNB(alpha=1.4).fit(X_train, y_train)\n",
    "\n",
    "#prediction columns\n",
    "train['predicted'] = nb.predict(X_train)\n",
    "test['predicted'] = nb.predict(X_test)\n",
    "\n",
    "#check for overfitness\n",
    "print(f'train score: {nb.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {nb.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy on train, confusion matrix, and classification report for naive bayes\n",
    "m.model_info(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89833bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes scores\n",
    "nb_accuracy = round(sklearn.metrics.accuracy_score(y_train, train.predicted),2)\n",
    "nb_precision = round(sklearn.metrics.precision_score(y_train, train.predicted, average='macro'),2)\n",
    "nb_recall = round(sklearn.metrics.recall_score(y_train, train.predicted, average='macro'),2)\n",
    "print('Scores for Naive Bayes!')\n",
    "print('---------------------------')\n",
    "print(f'Our baseline score is {baseline_score}')\n",
    "print(f'Accuracy score is {nb_accuracy}')\n",
    "print(f'Precision score is {nb_precision}')\n",
    "print(f'Recall score is {nb_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cbc1a9",
   "metadata": {},
   "source": [
    "<br>\n",
    "Multinomial Naive Bayes actually performs the exact same as our logistic regression. It predicted that every repository was JavaScript except for 1 which was predicted as Python. It is tied with our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd9e77",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Modeling Takeaways: \n",
    " - Random Forest, Logistic Regression, Naive Bayes do not predict Java or Go languages. Can probably be fixed with more data, and adjustment of hyperparameters\n",
    " - KNN performs the best at ~87% accuracy on train. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6f43f",
   "metadata": {},
   "source": [
    "<a id='test'></a>\n",
    "# Test\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7040cf7",
   "metadata": {},
   "source": [
    "Our best performing model: KNN\n",
    "\n",
    "Let's get a recap on how it did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bringing back our KNN model from above, just refreshing on its train and validate scores\n",
    "knn = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = knn.predict(X_train)\n",
    "test['predicted'] = knn.predict(X_test)\n",
    "\n",
    "print(f'train score: {knn.score(X_train, y_train):.2%}')\n",
    "print(f'validate score: {knn.score(X_validate, y_validate):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffca927",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's put it to the test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5615c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get accuracy score for test set predictions vs. test set actual results\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "#print the confusion matrix for test set predictions vs test set actual results\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "#print classification report \n",
    "print(classification_report(test.actual, test.predicted))\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "#train, validate, and test scores for KNN\n",
    "print(f'Our baseline score is {baseline_score*100}%')\n",
    "print(f'Training score: {knn.score(X_train, y_train):.2%}')\n",
    "print(f'Validate score: {knn.score(X_validate, y_validate):.2%}')\n",
    "print(f'Test score: {knn.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy = round(sklearn.metrics.accuracy_score(y_test, test.predicted),2)\n",
    "knn_precision = round(sklearn.metrics.precision_score(y_test, test.predicted, average='macro'),2)\n",
    "knn_recall = round(sklearn.metrics.recall_score(y_test, test.predicted, average='macro'),2)\n",
    "\n",
    "print(f'KNN accuracy score is {knn_accuracy}')\n",
    "print(f'KNN precision score is {knn_precision}')\n",
    "print(f'KNN recall score is {knn_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9801630",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "# Conclusion and Next Steps\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e86abe",
   "metadata": {},
   "source": [
    " - Using a combination of single words, bigrams, and trigrams, our best performing model was a KNN. \n",
    " - It beat the baseline by 28.82%. \n",
    " - Accuracy of 82%, precision of 82%, and recall of 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f89c61",
   "metadata": {},
   "source": [
    "With more time, we would like to use more repositories to potentially find more words that can help predict the programming language used. We'd also take more time to prepare our data to assure we are using meaningful readmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7ea36-fec2-4df4-baef-0cfbb62740c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
